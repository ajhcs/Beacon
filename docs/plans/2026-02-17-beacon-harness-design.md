# Beacon: Self-Improving Verification Harness for AI-Assisted Software Development

**Date:** 2026-02-17
**Status:** Approved
**Approach:** B+C (Composable Rust Engine with Proven Components + Progressive Layered Build)

---

## Table of Contents

1. [System Architecture Overview](#1-system-architecture-overview)
2. [Declarative IR Specification](#2-declarative-ir-specification)
3. [Beacon Core — Rust Engine Architecture](#3-beacon-core--rust-engine-architecture)
4. [Claude Code Integration](#4-claude-code-integration)
5. [The Self-Improvement Loop](#5-the-self-improvement-loop)
6. [Build Sequence](#6-build-sequence)

---

## 1. System Architecture Overview

Beacon is a self-improving verification system for AI-assisted software development. It ensures AI-generated code satisfies formally specified constraints through property-based simulation and runtime containment.

### Three Actors

- **Human** — Provides intent, approves formal specs. Never touches code.
- **AI Agent** (Claude) — Translates intent into formal specs via Socratic questioning. Generates code. Interprets failures and proposes fixes.
- **Beacon Core** (Rust, native) — The puppet master. Compiles specs, directs exploration, enforces constraints, contains the DUT.

### Two Nested Loops

**Outer loop — Spec Refinement** (AI + Human):

```
Human intent
  -> AI: Socratic questioning (until confidence threshold met)
  -> Declarative IR (JSON) <- human approves
  -> Beacon Core compiles IR -> State Machines + Refinement Types
  [If compilation fails: AI revises IR -> human re-approves]
```

**Inner loop — Verification** (Beacon Core + AI, autonomous):

```
AI generates code (DUT)
  -> Beacon Core loads DUT into WASM sandbox
  -> Beacon Core runs directed fuzzing against DUT
  -> Pass: verified software delivered
  -> Fail: failure report -> AI generates fix -> re-load -> re-verify
  -> Beacon Core adapts exploration (see Adaptation Boundaries below)
```

The outer loop runs until the spec is stable. The inner loop runs until the code satisfies the spec. Humans participate in the outer loop only.

### DUT Computation vs Test Computation

These are distinct execution domains, following the traversal patent's separation:

- **Test computation** (Beacon Core, native Rust): NDA traversal, state machine evaluation, constraint solving, Monte Carlo sampling, coverage tracking, adaptation directives. This is everything the verifier does *around* the DUT.
- **DUT computation** (WASM sandbox): The AI-generated code under test. Receives stimuli from Beacon Core, produces outputs. Isolated. No access to the verification state.

Beacon Core orchestrates test computation and injects it into the DUT's execution. The DUT never knows it's being tested — it just runs.

### Adaptation Boundaries

Modification directives during the inner loop **can** change:

- Exploration weights (bias toward under-explored paths)
- Traversal strategy (force/skip terminals, switch from random to targeted)
- NDA graph structure (add new paths discovered during exploration)
- Action routine bindings (swap in deeper assertions for a terminal)

Modification directives **cannot**:

- Weaken, relax, or remove any constraint in the approved spec
- Modify refinement type predicates
- Alter state machine transition rules defined in the IR

The spec is immutable physics once the human approves it. Adaptation is strictly about *how to explore*, never *what to enforce*.

### Concurrency Model

- **NDA traversal threads** — Multiple NDA instances can run concurrently, each exploring different paths through the protocol graph. These are test computation threads, running natively.
- **DUT thread** — The WASM sandbox runs in its own thread (or async task). Beacon Core's traversal threads coordinate stimuli to the DUT through a synchronized interface.
- Traversal threads and the DUT thread never share memory directly. Communication is through Beacon Core's orchestration layer.

### Integration

Beacon Core is a single native Rust binary exposed to Claude Code via MCP server (stdio transport). A Claude Code plugin provides skills (Socratic workflow) and hooks (action interception).

### Key Invariant

The AI never declares success. Only the Rust engine can promote code from "candidate" to "verified."

---

## 2. Declarative IR Specification

The Declarative IR is the single most important artifact in Beacon. It's the contract between human intent and machine enforcement — what the AI generates, what the human approves, and what the Rust engine treats as immutable law.

**Format:** JSON. Machine-generated by AI, machine-consumed by Beacon Core. Human review happens conversationally — the AI presents the spec in natural language; the human never reads raw JSON.

### Nine Sections

#### 2.1 Entities

Domain objects with typed fields. These are the model's nouns — Beacon Core maintains its own model instances independently of the DUT.

```json
{
  "entities": {
    "User": {
      "fields": {
        "id": { "type": "string", "format": "uuid" },
        "role": { "type": "enum", "values": ["admin", "member", "guest"] },
        "authenticated": { "type": "bool" }
      }
    },
    "Document": {
      "fields": {
        "id": { "type": "string", "format": "uuid" },
        "owner_id": { "type": "ref", "entity": "User" },
        "visibility": { "type": "enum", "values": ["private", "shared", "public"] },
        "deleted": { "type": "bool", "default": false }
      }
    }
  }
}
```

#### 2.2 Refinement Types

Constrained types with predicates. Predicates are **structured expressions** (JSON ASTs), not raw strings — no custom parser, no risk of accidental Turing-completeness.

Functions are classified as **derived** (pure, computed from model fields, can be SMT'd) or **observer** (calls into DUT, runtime-checked only).

```json
{
  "refinements": {
    "AuthenticatedUser": {
      "base": "User",
      "predicate": ["eq", ["field", "self", "authenticated"], true]
    },
    "OwnedDocument": {
      "base": "Document",
      "params": [{ "name": "actor", "type": "User" }],
      "predicate": ["eq", ["field", "self", "owner_id"], ["field", "actor", "id"]]
    },
    "AccessibleDocument": {
      "base": "Document",
      "params": [{ "name": "actor", "type": "User" }],
      "predicate": ["or",
        ["eq", ["field", "self", "visibility"], "public"],
        ["eq", ["field", "self", "owner_id"], ["field", "actor", "id"]],
        ["and",
          ["eq", ["field", "self", "visibility"], "shared"],
          ["neq", ["field", "actor", "role"], "guest"]
        ]
      ]
    }
  },
  "functions": {
    "canAccess": {
      "classification": "derived",
      "params": [{ "name": "u", "type": "User" }, { "name": "d", "type": "Document" }],
      "body": ["is", "d", "AccessibleDocument", { "actor": "u" }],
      "returns": "bool"
    },
    "checkAccessDUT": {
      "classification": "observer",
      "params": [{ "name": "u", "type": "User" }, { "name": "d", "type": "Document" }],
      "binding": "check_access",
      "returns": "bool"
    }
  }
}
```

**Model Truth vs Observed Behavior:** Derived functions compute against Beacon's own model state — if `canAccess` says a user shouldn't access a document, that's model truth. Observer functions query the DUT — if `checkAccessDUT` disagrees with `canAccess`, that's a **discrepancy**, which is exactly what Beacon is looking for.

#### 2.3 Protocols

Valid operation sequences using **composable grammar constructs**: `seq`, `alt`, `repeat`, `call`, `ref`. These map to the NDA structure from the 2008 patent. The engine compiles them down to traversable graphs internally.

```json
{
  "protocols": {
    "document_lifecycle": {
      "root": {
        "type": "seq",
        "children": [
          { "type": "call", "action": "create_document" },
          {
            "type": "repeat",
            "min": 0,
            "max": 50,
            "body": {
              "type": "alt",
              "branches": [
                {
                  "id": "read_path",
                  "weight": 40,
                  "guard": ["is", "doc", "AccessibleDocument", { "actor": "actor" }],
                  "body": { "type": "call", "action": "read" }
                },
                {
                  "id": "publish_path",
                  "weight": 25,
                  "guard": ["and",
                    ["is", "actor", "AuthenticatedUser"],
                    ["is", "doc", "OwnedDocument", { "actor": "actor" }]
                  ],
                  "body": { "type": "call", "action": "publish" }
                },
                {
                  "id": "archive_restore_cycle",
                  "weight": 20,
                  "body": {
                    "type": "seq",
                    "children": [
                      { "type": "call", "action": "archive" },
                      {
                        "type": "alt",
                        "branches": [
                          { "id": "restore_it", "weight": 60, "body": { "type": "call", "action": "restore" } },
                          { "id": "leave_archived", "weight": 40, "body": { "type": "ref", "protocol": "idle" } }
                        ]
                      }
                    ]
                  }
                },
                {
                  "id": "delete_path",
                  "weight": 15,
                  "guard": ["is", "actor", "AuthenticatedUser"],
                  "body": { "type": "call", "action": "delete" }
                }
              ]
            }
          }
        ]
      }
    }
  }
}
```

`ref` lets protocols compose — one protocol can reference another. `alt` carries weights that the exploration engine uses and adapts. `repeat` has explicit bounds. The engine compiles this grammar into an NDA graph for traversal.

#### 2.4 Effects

What actions do to **model state**. Without effects, the model can't track an evolving universe, and invariants have nothing to quantify over.

```json
{
  "effects": {
    "create_document": {
      "creates": { "entity": "Document", "assign": "doc" },
      "sets": [
        { "target": ["doc", "owner_id"], "value": ["field", "actor", "id"] },
        { "target": ["doc", "visibility"], "value": "private" },
        { "target": ["doc", "deleted"], "value": false }
      ]
    },
    "publish": {
      "sets": [
        { "target": ["doc", "visibility"], "value": "public" }
      ]
    },
    "delete": {
      "sets": [
        { "target": ["doc", "deleted"], "value": true }
      ]
    },
    "archive": {
      "sets": [
        { "target": ["doc", "visibility"], "value": "private" }
      ]
    },
    "restore": {
      "sets": [
        { "target": ["doc", "visibility"], "value": "shared" }
      ]
    },
    "read": {
      "sets": []
    }
  }
}
```

After each action, Beacon Core applies effects to its model, then checks invariants against the **model state** (not the DUT). Separately, it queries observers in the DUT and flags discrepancies between model truth and observed behavior.

#### 2.5 Properties

Global invariants and temporal constraints. Quantifiers are **bounded** over the current finite model set — decidable and implementable.

```json
{
  "properties": {
    "ownership_isolation": {
      "type": "invariant",
      "predicate": ["forall", "d", "Document", ["forall", "u", "User",
        ["implies",
          ["and",
            ["eq", ["field", "d", "visibility"], "private"],
            ["neq", ["field", "d", "owner_id"], ["field", "u", "id"]]
          ],
          ["not", ["derived", "canAccess", "u", "d"]]
        ]
      ]],
      "description": "No user can access a private document they don't own"
    },
    "auth_before_mutation": {
      "type": "temporal",
      "rule": ["before", { "tag": "mutating" }, ["eq", ["field", "actor", "authenticated"], true]],
      "description": "All mutations require authentication"
    },
    "delete_is_permanent": {
      "type": "temporal",
      "rule": ["after", "delete", ["never", "restore", { "same": "entity" }]],
      "description": "Deleted entities cannot be restored"
    }
  }
}
```

#### 2.6 Generators

How to create precondition states. To test `restore`, the engine needs a Document in archived state. Generators define **setup sequences** the engine can invoke to reach specific model states.

```json
{
  "generators": {
    "archived_document": {
      "description": "A document in archived state",
      "sequence": [
        { "action": "create_document", "with": { "actor": { "generate": "User", "where": ["eq", ["field", "self", "authenticated"], true] } } },
        { "action": "publish", "with": {} },
        { "action": "archive", "with": {} }
      ],
      "postcondition": ["eq", ["field", "doc", "visibility"], "private"]
    },
    "multi_user_scenario": {
      "description": "Two users with separate documents",
      "sequence": [
        { "action": "create_document", "with": { "actor": { "bind": "user_a" } } },
        { "action": "create_document", "with": { "actor": { "bind": "user_b" } } }
      ]
    }
  }
}
```

The engine can also discover setup sequences by reverse-traversing the protocol grammar — generators are an optimization to avoid deep search for common preconditions.

#### 2.7 Exploration

Declares the levers the engine can pull during directed fuzzing. Constraints are immutable; exploration policy is mutable.

```json
{
  "exploration": {
    "weights": {
      "scope": "per_alt_branch_and_model_state",
      "initial": "from_protocol",
      "decay": "per_epoch"
    },
    "directives_allowed": [
      { "type": "adjust_weight", "description": "Change weight on any alt branch (state-conditioned)" },
      { "type": "force", "description": "Force a specific terminal/action before others" },
      { "type": "skip", "description": "Skip a branch for bounded N iterations" },
      { "type": "loop_limit", "description": "Adjust repeat bounds within declared min/max" },
      { "type": "swap_observer", "description": "Bind a deeper observer to an action" }
    ],
    "adaptation_signals": [
      { "signal": "coverage_delta", "description": "New state/transition covered" },
      { "signal": "property_violation", "description": "An invariant or temporal rule failed" },
      { "signal": "discrepancy", "description": "Model truth diverged from DUT observation" },
      { "signal": "crash", "description": "DUT panicked or trapped in WASM" },
      { "signal": "timeout", "description": "DUT action exceeded time budget" },
      { "signal": "guard_failure", "description": "Guard prevented transition from current state" },
      { "signal": "coverage_plateau", "description": "Coverage delta rate approaching zero" }
    ],
    "strategy": {
      "initial": "pseudo_random_traversal",
      "fallback": "targeted_on_violation"
    },
    "epoch_size": 100,
    "coverage_floor_threshold": 0.05,
    "concurrency": {
      "mode": "deterministic_interleaving",
      "threads": 4
    }
  }
}
```

#### 2.8 Inputs

Declared input space + coverage constraints for the fracture/solve/abort pipeline.

```json
{
  "inputs": {
    "domains": {
      "actor_role": { "type": "enum", "values": ["admin", "member", "guest"] },
      "actor_authenticated": { "type": "bool" },
      "doc_visibility": { "type": "enum", "values": ["private", "shared", "public"] },
      "actor_is_owner": { "type": "bool" },
      "concurrent_actors": { "type": "int", "min": 1, "max": 8 }
    },
    "constraints": [
      { "name": "guest_never_admin", "rule": ["implies", ["eq", "actor_role", "guest"], ["neq", "actor_role", "admin"]] }
    ],
    "coverage": {
      "targets": [
        { "type": "all_pairs", "over": ["actor_role", "doc_visibility", "actor_is_owner"] },
        { "type": "each_transition", "machine": "document_lifecycle" },
        { "type": "boundary", "domain": "concurrent_actors", "values": [1, 2, 8] }
      ],
      "seed": 42,
      "reproducible": true
    }
  }
}
```

The engine fractures this input space into subspaces, solves for satisfying assignments, searches for unique vectors, and aborts unsatisfiable branches — directly implementing the 2013/2017 patent pipeline.

#### 2.9 Bindings

How abstract IR maps to concrete DUT artifacts. Includes **action metadata** and **event hooks** for inverse monitoring.

```json
{
  "bindings": {
    "runtime": "wasm",
    "entry": "main.wasm",
    "actions": {
      "create_document": {
        "function": "create_document",
        "args": ["actor_id"],
        "returns": { "type": "Document" },
        "mutates": true,
        "idempotent": false,
        "reads": [],
        "writes": ["Document"]
      },
      "read": {
        "function": "get_document",
        "args": ["actor_id", "doc_id"],
        "returns": { "type": "Document" },
        "mutates": false,
        "idempotent": true,
        "reads": ["Document"],
        "writes": []
      },
      "delete": {
        "function": "delete_document",
        "args": ["actor_id", "doc_id"],
        "returns": { "type": "void" },
        "mutates": true,
        "idempotent": false,
        "reads": [],
        "writes": ["Document"]
      }
    },
    "event_hooks": {
      "mode": "function_intercept",
      "observe": ["create_document", "publish", "delete", "archive", "restore"],
      "capture": ["args", "return_value", "side_effects"]
    }
  }
}
```

Action metadata (`mutates`, `reads`, `writes`) makes temporal rules like `before(any_mutation)` directly compilable — the engine knows which actions are mutations without inference. Event hooks enable inverse monitoring at the WASM host-call boundary.

### IR Design Principles

- **Declarative, not procedural** — Says *what* must hold, not *how* to check it.
- **Structured predicates** — JSON AST expressions, no string parsing, no custom parser, no risk of Turing-completeness.
- **Model Truth vs Observed Behavior** — Derived functions compute against Beacon's model; observers query the DUT. Discrepancies between them are findings.
- **Bounded quantifiers** — `forall`/`exists` over finite model sets. Decidable and implementable.
- **Function classification** — `derived` (pure, SMT-compatible) vs `observer` (DUT-calling, runtime-only). Explicit and enforced.
- **Guards reference refinement types** — Keeping the spec DRY.
- **Bindings are separate from semantics** — Same state machines + properties work across different DUT types. Only bindings change.

---

## 3. Beacon Core — Rust Engine Architecture

### Crate Structure (MVP)

Single binary, Cargo workspace with internal crates.

```
beacon/
  crates/
    beacon-ir/              IR types, JSON parsing, structural validation
    beacon-compiler/        IR -> compiled artifacts (bgraph, bcheck, bvif)
    beacon-model/           CoW model state, snapshot/rollback
    beacon-explore/         traversal + solver behind unified facade
      traversal/            (internal module) NDA walking, strategies, directives
      solver/               (internal module) fracture/solve/abort, vector pool
    beacon-sandbox/         WASM runtime via wasmtime
    beacon-vif/             Verification interface definitions
    beacon-core/            Orchestrator + monitor (merged until event model stabilizes)
      orchestrator/         (internal module) runs both loops, coordinates threads
      monitor/              (internal module) discrepancy detection, inverse monitoring
      mcp/                  (internal module) MCP server for Claude Code
```

When interfaces stabilize, `monitor` can split out of `beacon-core` and `traversal`/`solver` can split out of `beacon-explore`. Internal module boundaries make this a mechanical refactor.

### Phase 1: Compilation as Verification (`beacon-compiler`)

The cheapest verification layer — catch problems before anything runs.

**Step 1 — Parse.** Deserialize JSON IR via serde into typed AST (defined in `beacon-ir`). Malformed JSON fails here.

**Step 2 — Structural validation.**

- All `ref` targets resolve (no dangling protocol references)
- All entity references in refinement types exist
- All action names in protocols have matching effects and bindings
- No cycles in protocol `ref` chains (or explicitly marked recursive with bounds)
- All `alt` weights are non-negative and at least one branch per `alt` is non-zero
- All `repeat` has `min <= max` and `max` is finite
- All function params have declared types that exist as entities

**Step 3 — Predicate compilation.** Walk JSON AST expressions and compile into internal expression IR that can be:

- **Evaluated** directly against model state (runtime invariant checking)
- **Translated to SMT-LIB** (solver-backed reasoning on derived functions)
- **Type-checked** — every field reference resolves to a declared entity field with the right type

**Step 4 — Protocol compilation.** Compile grammar constructs (`seq`, `alt`, `repeat`, `call`, `ref`) into NDA graphs:

- Each `call` becomes a terminal node
- Each `alt` becomes a branch point with weighted edges
- Each `repeat` becomes a loop structure with counter bounds
- Each `ref` inlines or links to the referenced protocol's graph
- Result: traversable directed graph with metadata on every edge

**Step 5 — Input space compilation.** Compile domains, constraints, and coverage targets into solver-ready form (SMT-LIB assertions, finite integer domains, coverage constraint sets).

**Step 6 — Generator compilation.** Compile setup sequences into executable plans, pre-computing expected model state after each generator completes.

**Compiled artifacts:** Memory-mappable binary formats for zero-overhead fuzzing:

- `*.bgraph` — binary NDA graph (nodes, edges, weights, guard indices)
- `*.bcheck` — compiled predicate bytecode
- `*.bvif` — compiled verification interface (WASM import/export expectations)

### Phase 2: Directed Fuzzing — The Monte Carlo Engine

#### Solver Engine (`beacon-explore/solver`)

Implements the fracture/solve/abort pipeline from the 2013/2017 patents. Runs in a **dedicated solver thread pool** (Rayon), never in the hot fuzzing loop.

```
Given: input space domains + constraints + coverage targets

1. Fracture input space by first variable
   -> produces subspaces

2. For each subspace, in parallel:
   a. Solve: any satisfying assignment? (SAT check via Z3/varisat)
   b. If UNSAT -> abort this subspace immediately
   c. If SAT -> search for unique satisfying vectors
      - generate assignments covering uncovered targets
      - hash assignments to avoid redundancy
      - stop when coverage targets for this subspace are met

3. Hierarchical: fracture subspaces further if coverage insufficient

4. Aggregate: non-redundant test vector pool, reproducible given same seed
```

Per-stage RNG seeding: each fracture stage has its own `ChaCha8Rng::seed_from(seed + stage_id)` for deterministic vector generation.

Vectors are stored in a **lockfree queue**, indexed by coverage target. Traversal threads draw from the queue without blocking the solver.

#### Traversal Engine (`beacon-explore/traversal`)

Implements the object stack + strategy stack from the 2008 patent.

```
Initialize:
  push initial strategy (pseudo-random traversal) onto strategy stack
  push root protocol node onto object stack

Loop:
  pop object from object stack
  delegate to current strategy:
    terminal (call) -> execute action pipeline
    alt -> select branch using state-conditioned weights
    seq -> push children in reverse order
    repeat -> push body N times (chosen by strategy within bounds)
    ref -> push referenced protocol's root
```

#### Action Pipeline

The executor is dumb pipes. The strategy is the brain.

1. Strategy selects next terminal (call)
2. Check guard against model state
3. If guard fails -> report `guard_failure` signal to strategy. Strategy decides: pick different branch, explicitly schedule generator (visible in trace), skip and adapt weights. **The executor never "helps".**
4. If guard passes -> select input vector from pre-generated pool
5. Call into WASM sandbox with concrete arguments (mapped through verification adapter)
6. Capture DUT response (return value, trapped/panicked state, execution time)
7. Apply effects to model state
8. Check model invariants (derived, against model)
9. Query observers (call into DUT for observable state)
10. Compare model vs observed — divergence is a discrepancy finding
11. Check temporal trace
12. Emit signals
13. Process directives via coordinator

### Phase 3: Sandboxed Execution — The WASM Container (`beacon-sandbox`)

Wasmtime configuration for the puppet-master relationship.

**Isolation guarantees:**

- No filesystem access (no WASI FS)
- No network access (no WASI sockets)
- No environment variables
- No clock access (deterministic execution)
- Memory capped (configurable, e.g., 256MB)
- CPU metered via wasmtime fuel (configurable time budget per action)

**Snapshot/restore:** Wasmtime supports instance snapshots. After running a generator sequence, snapshot the instance. Subsequent test vectors needing the same precondition restore from snapshot. **Critical: every WASM snapshot is paired with a model generation number. Restore atomically restores both WASM instance AND model state. If either fails, both roll back.**

#### Verification Adapter Layer (`beacon-vif`)

Auto-generated from IR bindings during compilation. Bridges the automata world and the DUT.

- **Forward direction (Beacon -> DUT):** Action stubs serialize arguments, call WASM exports, deserialize returns
- **Reverse direction (DUT -> Beacon):** Event interceptors at WASM host-call boundary emit action events for inverse monitoring
- **Observer probes:** Call into DUT for observable state, tagged as `ObserverResult` (never confused with model truth)
- **Type marshaling:** Between Beacon's model types and WASM's linear memory
- **Interface validation:** At DUT load time, verify WASM module exports match declared bindings

### Model State (`beacon-model`)

Copy-on-Write for efficient state forking:

```
ModelState:
  entities: CoW<HashMap<EntityId, CoW<Entity>>>
  trace: CoW<Vec<TraceEntry>>
  generation: u64  (monotonic, incremented on every mutation)

Operations:
  fork() -> new ModelState sharing underlying data (zero-copy until mutation)
  rollback(snapshot_id) -> restore to captured generation
  snapshot() -> (generation, wasm_snapshot) — always paired
```

### Thread Architecture

```
1. MCP Server (Tokio runtime, async):
   - Handles Claude Code communication
   - Never does compute work
   - Spawns work onto other pools via channels

2. Solver Pool (Rayon or dedicated threads):
   - CPU-bound constraint solving
   - Feeds vector pool
   - Independent of Tokio reactor

3. Traversal Pool (Rayon):
   - CPU-bound NDA traversal + WASM invocation
   - Each thread owns its own WASM instance + model fork
   - Draws from vector pool
   - Pushes signals/findings to coordinator via crossbeam channels

4. Coordinator (dedicated thread):
   - Aggregates coverage, signals, findings
   - Issues directives to traversal threads
   - Decides termination
   - Reports results to MCP server via channel
```

Tokio never touches CPU-bound work. Rayon never touches async I/O.

### External Dependencies

| Crate | Purpose | Rationale |
|-------|---------|-----------|
| `wasmtime` | WASM sandbox | Production-proven (Cloudflare, Fastly). WASI-configurable. Snapshot/restore. Fuel metering. |
| `z3-sys` or `varisat` | Constraint solving | Z3 is SMT gold standard. Varisat is pure Rust SAT. Fracture/solve/abort needs a real solver. |
| `serde` + `serde_json` | IR parsing | Zero-copy JSON deserialization. |
| `rayon` | CPU-bound parallelism | Traversal + solver thread pools. |
| `tokio` | Async I/O | MCP server only. |
| `crossbeam` | Lock-free channels | Coordinator <-> traversal thread communication. |

---

## 4. Claude Code Integration

### MCP Server Interface

Beacon Core exposes itself to Claude Code as a stdio MCP server. All tools thread through a `campaign_id` to prevent cross-talk.

**Tool lifecycle:**

```
beacon_compile(ir_json)
  -> { campaign_id, result: pass|errors, budget: { min_iterations, min_timeout } }

beacon_load_dut(campaign_id, wasm_bytes)
  -> { result: pass|errors, interface_check: { missing_exports, type_mismatches } }

beacon_fuzz_start(campaign_id, extra_iterations?, concurrency_mode?)
  -> { status: "started", estimated_duration }

beacon_fuzz_status(campaign_id)
  -> {
      state: "running" | "complete" | "aborted",
      progress: { iterations_done, iterations_total, percent },
      budget_consumed: { wall_time, cpu_time },
      coverage: { targets_hit, targets_total, percent },
      coverage_delta_rate: f64,
      findings_count: u32
    }

beacon_findings(campaign_id, since_seqno?)
  -> {
      findings: [Finding],
      next_seqno: u64,
      total_findings: u32
    }

beacon_reproduce(campaign_id, finding_id, mode?: "deterministic" | "verbose")
  -> {
      reproduced: bool,
      replay_capsule: ReplayCapsule,
      trace: [TraceEntry]
    }

beacon_coverage(campaign_id)
  -> {
      targets: [{ target, status: "hit" | "pending" | "unreachable", hit_count }],
      summary: { hit, pending, unreachable, percent }
    }

beacon_abort(campaign_id)
  -> { final_status }
```

### Fuzzing Budget Control

The AI does **not** control fuzzing parameters directly. Beacon Core computes minimums from IR complexity:

```
min_iterations = f(|states| x |transitions| x |input_domain_size| x |coverage_targets|)
```

The AI can request MORE iterations beyond the minimum, never less. Smoke runs (low iteration, advisory) don't count as verification campaigns.

### Model State Visibility

- **Live model state during fuzzing: OPAQUE.** The AI cannot query or manipulate the model while the engine runs.
- **Historical model state in findings: READ-ONLY SNAPSHOT.** Findings include a frozen model snapshot at the point of failure — forensic, not live.

### Replay Capsules

Every finding carries a replay capsule for deterministic reproduction:

```
ReplayCapsule {
  ir_hash: SHA256,
  compiled_graph_hash: SHA256,
  dut_wasm_hash: SHA256,
  global_seed: u64,
  thread_seed: u64,
  solver_stage_stack: [SolverStage],
  traversal_log: [TraversalEvent],
  event_sequence_key: u64,
  serialized_event_log: Vec<Event>,
}
```

`beacon_reproduce` runs in **single-thread deterministic mode by default**, regardless of the original campaign's concurrency mode.

### The Socratic Workflow (Skill)

A Claude Code skill guides the AI through extracting formal constraints from human intent.

**Phase 1 — Domain Discovery:** Identify entities and relationships. Build Entities section.

**Phase 2 — Constraint Extraction:** Identify what must always/never be true. Build Refinements, Properties sections.

**Phase 3 — Behavioral Modeling:** Identify valid operation sequences. Build Protocols, Effects sections.

**Phase 4 — Edge Case Probing:** Stress-test gathered constraints with adversarial scenarios. Refine Properties, Protocols, add Generators.

**Phase 5 — Confidence Assessment:** Check for unconstrained entities, unguarded actions, coverage gaps. Loop back if gaps found.

**Phase 6 — Human Presentation:** Present spec conversationally (not raw JSON) for human approval.

### The Verification Loop (Skill)

Once the IR compiles, a second skill governs the inner loop:

1. Compile DUT to WASM
2. Load and fuzz (`beacon_load_dut` -> `beacon_fuzz_start`)
3. Interpret findings (`beacon_findings` with incremental polling via `since_seqno`)
4. Fix and re-verify (address ALL findings, not just the first)
5. Coverage check — only complete when all targets met AND zero findings

### Hooks

**PostToolUse on Write/Edit:** Triggers WASM recompilation + smoke fuzz. Advisory only — doesn't count as verification.

**Stop hook (gate):** Blocks completion unless:

- Active campaign exists
- `beacon_fuzz_status` -> state == "complete"
- `beacon_findings` -> total_findings == 0
- `beacon_coverage` -> percent >= threshold

### AI Constraints

The AI **cannot**:

- Modify the compiled IR after human approval
- See or manipulate live model state
- Issue adaptation directives
- Mark findings as "expected" or "won't fix"
- Adjust coverage targets
- Set fuzzing iterations below the computed minimum

The AI is a powerful code generator that proposes and fixes. Beacon is the judge. The human is the lawmaker.

---

## 5. The Self-Improvement Loop

Three layers of improvement operating at different timescales.

### Layer 1: Intra-Campaign Adaptation (seconds, autonomous)

Within a single fuzzing campaign, the engine adjusts exploration based on observed signals.

#### Signal Total Ordering

Traversal threads emit `SignalEvent { thread_id, local_step, signal_type, payload_hash }`. The coordinator collects signals into fixed-size epochs, assigns monotonic `signal_seqno` (sorted by thread_id then local_step), processes directives in order, and applies them at epoch boundaries atomically. Same inputs -> same directive history regardless of thread scheduling.

#### State-Conditioned Weights

Weights are keyed by `(AltBranchId, AbstractModelStateId)`, not globally:

- `AbstractModelStateId` = hash of model fields referenced by guards in the alt block
- Guard failures teach "branch B is invalid WHEN model is in state S" not "branch B is globally unproductive"
- Key space is bounded by the product of guard-referenced field domains

#### Signal -> Directive Mappings

| Signal | Response |
|--------|----------|
| `coverage_delta` | `adjust_weight` — increase weight on the branch that led here |
| `property_violation` | `force` nearby branches + `swap_observer` for deeper checking |
| `discrepancy` | `force` + `loop_limit(increase)` around the divergent path |
| `crash` | `force` with boundary values and related input vectors |
| `timeout` | **Two-step:** (1) halve fuel, retry once — if completes, emit performance finding; (2) if still hangs, bounded `skip` + timeout finding |
| `guard_failure` | `adjust_weight(decrease)` at `(branch, current_model_state)` — state-conditioned |
| `coverage_plateau` | Compute reachable uncovered targets, push `ForceStrategy` for each feasible target |

#### Strategy Stack

```
StrategyStack = [
  PseudoRandomTraversal { seed, weights },   // base: explore broadly
]

On coverage_plateau:
  push TargetedTraversal { uncovered_targets }

On property_violation:
  push InvestigationTraversal {
    focus_region: violation_path,
    radius: 2,
    budget: 500
  }

On budget exhausted:
  pop back to previous strategy (with updated weights)
```

Depth limit: 4. Oldest popped on overflow.

#### Weight Decay and Normalization

Per epoch:

- Taken branches: slight decay (prevent fixation)
- Finding-yielding branches: boost proportional to severity
- Guard-failing branches (from current state): decay
- All weights in an alt block renormalized to sum to 100

### Layer 2: Cross-Campaign Learning (minutes to hours)

When the AI fixes code and starts a new campaign, the engine carries forward knowledge.

**Persists across campaigns (same IR):**

- Previous finding replay capsules (full, not just summaries)
- Learned state-conditioned weights (with 0.8 decay per campaign)
- Hot regions with reproduction tracking
- Effective generator shortcuts

**Resets across campaigns:**

- Model state (fresh)
- WASM instance (fresh DUT)
- Traversal traces (new campaign)
- Finding list (re-verify everything, don't assume fixed)

**Re-regression priority on campaign start:**

1. Replay all previous finding capsules against new DUT (confirm fixes, catch regressions)
2. Explore hot regions with boosted weights
3. Resume coverage-driven exploration

**Invalidation:** If a previously hot region fails to reproduce after K consecutive campaigns (default: 3), apply aggressive decay (0.2 instead of 0.8) to avoid overfitting to fixed bugs. Replay capsule is kept for future regression detection.

### Layer 3: Cross-Spec Evolution (future, not MVP)

Track which properties are frequently violated, which entity relationships produce the most discrepancies, which coverage targets are consistently unreachable. Feed back into the Socratic questioning skill.

### Adaptation Invariants

1. **Constraints are immutable.** Adaptation changes exploration policy, never the spec.
2. **Weights never go to permanent zero UNLESS provably unreachable** (static reachability or solver UNSAT). Proof artifact logged. Zero is reversible on IR recompilation.
3. **All directives are logged** with the signal that triggered them.
4. **Adaptation is deterministic given the same signal sequence** (epoch-barrier total ordering).
5. **Strategy stack depth limit** (default: 4).
6. **Cross-campaign memory decays** (0.8 per campaign, 0.2 for non-reproducing findings after K attempts).
7. **Coverage floor** — adaptation cannot reduce probability mass of uncovered-target-reaching regions below minimum threshold (default: 5% of total weight budget).

---

## 6. Build Sequence

Progressive layers, each independently valuable.

### Layer 0: Foundation + IR Compiler

**Crates:** `beacon-ir`, `beacon-compiler` (structural validation + predicate compilation)

**Delivers:**
- Parse Declarative IR JSON into typed AST
- Validate structural consistency
- Compile predicates into evaluable expression trees
- Compile protocols into NDA graphs
- Emit compiled binary artifacts (`.bgraph`, `.bcheck`)
- Report structured compilation errors

**Milestone:** The outer loop (Socratic questioning -> IR -> compile -> revise) is functional. The AI can iterate on specs with the human before writing any code.

**Claude Code integration:** Basic MCP server with `beacon_compile`. Socratic questioning skill.

**Scope:** ~2-3K lines of Rust.

### Layer 1: Model State + Property Checking

**Crates:** `beacon-model`, `beacon-compiler` (extended)

**Delivers:**
- CoW model state with snapshot/rollback
- Effect application, derived function evaluation
- Invariant checking after every effect
- Temporal property checking against action traces
- Input space compilation, generator compilation

**Milestone:** Beacon can simulate the protocol against its own model without a DUT. Catches spec-level bugs ("your invariant contradicts your effects").

**Claude Code integration:** `beacon_simulate` tool.

**Scope:** ~2-3K lines.

### Layer 2: WASM Sandbox + Verification Adapter

**Crates:** `beacon-sandbox`, `beacon-vif`

**Delivers:**
- WASM loading via wasmtime with full isolation
- Auto-generated verification adapter from bindings
- Interface validation at load time
- Single action execution with return capture
- Snapshot/restore paired with model state
- Event hooks for inverse monitoring

**Milestone:** First time model truth meets observed behavior. Discrepancies are detectable. Puppet-master relationship established.

**Claude Code integration:** `beacon_load_dut`, `beacon_execute_action`.

**Scope:** ~2-3K lines.

### Layer 3: Solver + Vector Generation

**Crates:** `beacon-explore` (solver module)

**Delivers:**
- Input space fracturing
- Constraint solving via Z3/varisat
- Unique vector search with abort on UNSAT
- Hierarchical fracturing
- Per-stage RNG seeding for reproducibility
- Pre-generated vector pool with lockfree queue

**Milestone:** Minimal non-redundant test vector generation from declared input spaces. Usable standalone as a test data generator.

**Claude Code integration:** `beacon_generate_vectors`.

**Scope:** ~3-4K lines.

### Layer 4: Traversal Engine + Directed Fuzzing

**Crates:** `beacon-explore` (traversal module), `beacon-core`

**Delivers:**
- Object stack + strategy stack NDA traversal
- State-conditioned weight selection
- Full action pipeline (guard -> vector -> sandbox -> effects -> invariants -> observers -> compare -> signals)
- Signal total ordering via epoch barriers
- Directive processing
- Strategy stack (PseudoRandom, Targeted, Investigation, Force)
- Concurrent traversal threads + coordinator
- Replay capsule generation
- Deterministic interleaving and true parallel modes

**Milestone:** The full inner verification loop is operational. This is the core product.

**Claude Code integration:** `beacon_fuzz_start`, `beacon_fuzz_status`, `beacon_findings`, `beacon_reproduce`, `beacon_coverage`, `beacon_abort`. Inner loop skill. Stop hook. Smoke-check hook.

**Scope:** ~4-5K lines.

### Layer 5: Adaptation + Cross-Campaign Learning

**Crates:** `beacon-core` (extended)

**Delivers:**
- All signal -> directive adaptation rules
- Weight decay/normalization per epoch
- Coverage floor enforcement
- Timeout two-step response
- Plateau -> Force compilation
- Provable-unreachability zero-weight with proof artifacts
- Cross-campaign memory persistence
- Invalidation triggers
- Re-regression priority ordering

**Milestone:** The system genuinely improves over time. Successive campaigns are smarter.

**Scope:** ~2-3K lines.

### Layer 6: Polish + Production Hardening

**Delivers:**
- Comprehensive error messages
- Campaign analytics (coverage curves, finding rates, adaptation effectiveness)
- Configuration validation
- Resource limits (memory, CPU, duration caps)
- Graceful degradation
- IR schema documentation for AI consumption

**Scope:** ~1-2K lines.

### Build Parallelism

```
Layer 0 (foundation)
  |
  +-- Layer 1 (model)        \
  +-- Layer 2 (sandbox)       |-- parallel, converge at Layer 4
  +-- Layer 3 (solver)       /
  +-- Socratic skill (parallel with all engine work)
  |
  Layer 4 (traversal + core) -- convergence point
  |
  Layer 5 (adaptation)
  |
  Layer 6 (polish)
```

### Total Estimated Scope

| Layer | Lines (est.) | Cumulative |
|-------|-------------|------------|
| 0: IR Compiler | ~2-3K | ~2-3K |
| 1: Model State | ~2-3K | ~5-6K |
| 2: WASM Sandbox | ~2-3K | ~7-9K |
| 3: Solver | ~3-4K | ~10-13K |
| 4: Traversal + Core | ~4-5K | ~14-18K |
| 5: Adaptation | ~2-3K | ~16-21K |
| 6: Polish | ~1-2K | ~17-23K |

Roughly 17-23K lines of Rust for the complete system, excluding tests. Each layer is testable independently.

---

## Patent Lineage

The mechanisms in this design trace directly to:

- **US20080059842A1 (2008):** NDA-based protocol specification, object stack + strategy stack traversal, terminal action routines, weighted alternatives, modification directives (adjust weights, force, skip, swap), strategy composition, verification interface module concept.
- **US20130298102A1 (2013):** Input space fracturing, parallel solve + search with abort, constraint-based test generation, solver interoperability.
- **US9619598 (2017):** Hierarchical fracturing, unique vector search, reproducibility via seeded generation, coverage-driven constraint solving, software DUT application.
